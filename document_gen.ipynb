{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-19T12:40:36.914597Z",
     "start_time": "2025-07-19T12:40:36.878924Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fpdf import FPDF\n",
    "import time\n",
    "import unicodedata\n",
    "import re\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import json\n",
    "\n",
    "# Enhanced text cleaning function\n",
    "def clean_text_for_pdf(text):\n",
    "    \"\"\"Enhanced text cleaning for better PDF compatibility\"\"\"\n",
    "    replacements = {\n",
    "        '\\u2192': ' -> ', '\\u2190': ' <- ', '\\u2022': '* ',\n",
    "        '\\u201c': '\"', '\\u201d': '\"', '\\u2018': \"'\", '\\u2019': \"'\",\n",
    "        '\\u2013': '-', '\\u2014': '-', '\\u00a0': ' ', '\\u2026': '...',\n",
    "        '\\u00ae': '(R)', '\\u00a9': '(C)', '\\u2122': '(TM)'\n",
    "    }\n",
    "\n",
    "    for unicode_char, replacement in replacements.items():\n",
    "        text = text.replace(unicode_char, replacement)\n",
    "\n",
    "    # Remove extra whitespace and normalize\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    return text.strip()"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:41:24.769371Z",
     "start_time": "2025-07-19T12:41:24.752840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enhanced web scraper with multiple content extraction strategies\n",
    "def enhanced_scrape_content(url, max_retries=3):\n",
    "    \"\"\"Enhanced web scraping with fallback strategies\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Remove unwanted elements\n",
    "            for element in soup(['script', 'style', 'nav', 'header', 'footer',\n",
    "                               'aside', 'advertisement', 'ad', 'popup']):\n",
    "                element.decompose()\n",
    "\n",
    "            # Try multiple content extraction strategies\n",
    "            content_strategies = [\n",
    "                # Strategy 1: Look for main content areas\n",
    "                lambda: extract_main_content(soup),\n",
    "                # Strategy 2: Look for article content\n",
    "                lambda: extract_article_content(soup),\n",
    "                # Strategy 3: Extract all paragraphs\n",
    "                lambda: extract_paragraph_content(soup),\n",
    "                # Strategy 4: Fallback to body text\n",
    "                lambda: soup.get_text()\n",
    "            ]\n",
    "\n",
    "            for strategy in content_strategies:\n",
    "                try:\n",
    "                    content = strategy()\n",
    "                    if content and len(content.strip()) > 500:  # Minimum content threshold\n",
    "                        return clean_text_for_pdf(content)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # If all strategies fail, return basic text\n",
    "            return clean_text_for_pdf(soup.get_text())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for {url}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "    return f\"Failed to scrape content from {url}\"\n",
    "\n",
    "def extract_main_content(soup):\n",
    "    \"\"\"Extract content from main content areas\"\"\"\n",
    "    main_selectors = [\n",
    "        'main', 'article', '[role=\"main\"]', '.main-content',\n",
    "        '.content', '.post-content', '.entry-content', '.article-body'\n",
    "    ]\n",
    "\n",
    "    for selector in main_selectors:\n",
    "        elements = soup.select(selector)\n",
    "        if elements:\n",
    "            return ' '.join([elem.get_text().strip() for elem in elements])\n",
    "    return None\n",
    "\n",
    "def extract_article_content(soup):\n",
    "    \"\"\"Extract article-specific content\"\"\"\n",
    "    content_parts = []\n",
    "\n",
    "    # Get title\n",
    "    title = soup.find('h1') or soup.find('title')\n",
    "    if title:\n",
    "        content_parts.append(f\"Title: {title.get_text().strip()}\\n\\n\")\n",
    "\n",
    "    # Get all paragraphs within article or main content\n",
    "    paragraphs = soup.select('article p, main p, .content p, .post p')\n",
    "    if not paragraphs:\n",
    "        paragraphs = soup.find_all('p')\n",
    "\n",
    "    for p in paragraphs:\n",
    "        text = p.get_text().strip()\n",
    "        if len(text) > 50:  # Filter out very short paragraphs\n",
    "            content_parts.append(text)\n",
    "\n",
    "    return '\\n\\n'.join(content_parts)\n",
    "\n",
    "def extract_paragraph_content(soup):\n",
    "    \"\"\"Extract all meaningful paragraphs\"\"\"\n",
    "    paragraphs = soup.find_all('p')\n",
    "    content = []\n",
    "\n",
    "    for p in paragraphs:\n",
    "        text = p.get_text().strip()\n",
    "        if len(text) > 30 and not any(skip in text.lower() for skip in\n",
    "                                     ['cookie', 'privacy policy', 'terms of service']):\n",
    "            content.append(text)\n",
    "\n",
    "    return '\\n\\n'.join(content)"
   ],
   "id": "e355fa890703965c",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:47:00.396422Z",
     "start_time": "2025-07-19T12:47:00.390747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enhanced_sources = {\n",
    "    'ai_agents_overview': 'https://cloud.google.com/discover/what-are-ai-agents',\n",
    "    'ai_agents_architecture': 'https://www.ibm.com/topics/ai-agents',\n",
    "    'ai_agents_types': 'https://research.google/blog/chain-of-agents-large-language-models-collaborating-on-long-context-tasks/',  # UPDATED\n",
    "\n",
    "    'langchain_intro': 'https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/',\n",
    "    'langchain_components': 'https://python.langchain.com/docs/get_started/introduction',\n",
    "    'langchain_chains': 'https://python.langchain.com/api_reference/langchain/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html',  # UPDATED\n",
    "\n",
    "    'langgraph_overview': 'https://langchain-ai.github.io/langgraph/',\n",
    "    'langgraph_tutorial': 'https://python.langchain.com/docs/langgraph',\n",
    "\n",
    "    'langsmith_platform': 'https://www.ibm.com/think/topics/langsmith',\n",
    "    'langsmith_features': 'https://docs.smith.langchain.com/',\n",
    "\n",
    "    'rag_overview': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation',\n",
    "    'rag_implementation': 'https://arxiv.org/pdf/2005.11401.pdf',  # UPDATED - Direct PDF link\n",
    "    'rag_best_practices': 'https://www.pinecone.io/learn/retrieval-augmented-generation/',\n",
    "\n",
    "    'vector_databases': 'https://en.wikipedia.org/wiki/Vector_database',\n",
    "    'vector_db_comparison': 'https://www.pinecone.io/learn/vector-database/',\n",
    "    'chromadb_guide': 'https://docs.trychroma.com/',\n",
    "\n",
    "    'embeddings_overview': 'https://simplai.ai/docs/User-guide/vector-embedding',\n",
    "    'sentence_transformers': 'https://www.sbert.net/',\n",
    "    'openai_embeddings': 'https://airbyte.com/data-engineering-resources/openai-embeddings',  # UPDATED\n",
    "\n",
    "    'transformers_architecture': 'https://www.ibm.com/think/topics/transformer-model',\n",
    "    'attention_mechanism': 'https://en.wikipedia.org/wiki/Attention_(machine_learning)',\n",
    "    'transformer_tutorial': 'https://jalammar.github.io/illustrated-transformer/',\n",
    "\n",
    "    'prompt_engineering': 'https://www.promptingguide.ai/',\n",
    "    'chain_of_thought': 'https://arxiv.org/abs/2201.11903',\n",
    "    'few_shot_prompting': 'https://arxiv.org/abs/2005.14165',\n",
    "\n",
    "    'fine_tuning_overview': 'https://docs.truefoundry.com/docs/finetuning-a-model-from-the-model-catalogue',\n",
    "    'llm_training': 'https://huggingface.co/blog/how-to-train',\n",
    "\n",
    "    'multimodal_overview': 'https://en.wikipedia.org/wiki/Multimodal_learning',\n",
    "    'vision_language_models': 'https://cdn.openai.com/papers/GPTV_System_Card.pdf',  # UPDATED - Direct PDF\n",
    "\n",
    "    'mcp_protocol': 'https://huggingface.co/blog/Kseniase/mcp',\n",
    "    'model_context_protocol': 'https://modelcontextprotocol.io/',\n",
    "\n",
    "    'pretraining_methods': 'https://toloka.ai/blog/pre-training-in-llm-development/',\n",
    "    'scaling_laws': 'https://arxiv.org/abs/2001.08361'\n",
    "}\n"
   ],
   "id": "bb4977f7a6790b09",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:43:38.804530Z",
     "start_time": "2025-07-19T12:43:38.797278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enhanced PDF document class\n",
    "class PDFDocument:\n",
    "    def __init__(self, title):\n",
    "        self.pdf = FPDF()\n",
    "        self.pdf.add_page()\n",
    "        self.pdf.set_font(\"Arial\", \"B\", 16)\n",
    "        clean_title = clean_text_for_pdf(title)\n",
    "        self.pdf.cell(200, 10, txt=clean_title, ln=True, align='C')\n",
    "        self.pdf.ln(10)\n",
    "\n",
    "    def add_section(self, title, content):\n",
    "        clean_title = clean_text_for_pdf(title)\n",
    "        clean_content = clean_text_for_pdf(content)\n",
    "\n",
    "        self.pdf.set_font(\"Arial\", \"B\", 14)\n",
    "        self.pdf.cell(200, 10, txt=clean_title, ln=True)\n",
    "        self.pdf.set_font(\"Arial\", size=11)\n",
    "\n",
    "        lines = clean_content.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if len(line) > 90:\n",
    "                words = line.split(' ')\n",
    "                current_line = \"\"\n",
    "                for word in words:\n",
    "                    if len(current_line + word) < 90:\n",
    "                        current_line += word + \" \"\n",
    "                    else:\n",
    "                        if current_line.strip():\n",
    "                            self.pdf.cell(200, 6, txt=current_line.strip(), ln=True)\n",
    "                        current_line = word + \" \"\n",
    "                if current_line.strip():\n",
    "                    self.pdf.cell(200, 6, txt=current_line.strip(), ln=True)\n",
    "            else:\n",
    "                self.pdf.cell(200, 6, txt=line, ln=True)\n",
    "        self.pdf.ln(5)\n",
    "\n",
    "    def save(self, filename):\n",
    "        try:\n",
    "            self.pdf.output(filename)\n",
    "            print(f\"Successfully saved {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {filename}: {e}\")"
   ],
   "id": "d86d8d1edc38dfa0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:48:08.827245Z",
     "start_time": "2025-07-19T12:47:14.721323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enhanced document creation with more detailed content\n",
    "def create_comprehensive_documents():\n",
    "    print(\"Starting comprehensive document creation with enhanced web scraping...\")\n",
    "\n",
    "    # Scrape all sources with progress tracking\n",
    "    scraped_content = {}\n",
    "    total_sources = len(enhanced_sources)\n",
    "\n",
    "    for i, (key, url) in enumerate(enhanced_sources.items(), 1):\n",
    "        print(f\"Scraping {i}/{total_sources}: {key}...\")\n",
    "        scraped_content[key] = enhanced_scrape_content(url)\n",
    "        time.sleep(1)  # Respectful crawling\n",
    "\n",
    "    # Document 1: AI Agents - Comprehensive Guide\n",
    "    doc1 = PDFDocument(\"AI Agents: Architecture, Types, and Implementation - Comprehensive Guide\")\n",
    "\n",
    "    # Enhanced AI Agents content\n",
    "    ai_agents_content = f\"\"\"\n",
    "INTRODUCTION TO AI AGENTS\n",
    "{scraped_content.get('ai_agents_overview', '')}\n",
    "\n",
    "AI AGENT ARCHITECTURE AND COMPONENTS\n",
    "{scraped_content.get('ai_agents_architecture', '')}\n",
    "\n",
    "Core Architectural Components:\n",
    "- Perception Module: Sensory input processing and environment observation\n",
    "- Reasoning Engine: Decision-making algorithms using symbolic and neural approaches\n",
    "- Planning System: Goal decomposition and action sequence generation\n",
    "- Memory Management: Short-term working memory and long-term knowledge storage\n",
    "- Action Execution: Tool integration and environment interaction capabilities\n",
    "- Learning Module: Adaptation and improvement from experience\n",
    "\n",
    "TYPES AND CLASSIFICATIONS OF AI AGENTS\n",
    "{scraped_content.get('ai_agents_types', '')}\n",
    "\n",
    "Agent Classification Framework:\n",
    "- Reactive Agents: Stimulus-response behavior without internal state\n",
    "- Deliberative Agents: Goal-oriented reasoning with internal world models\n",
    "- Hybrid Agents: Combination of reactive and deliberative capabilities\n",
    "- Multi-agent Systems: Collaborative and competitive agent interactions\n",
    "- Autonomous Agents: Self-directed operation with minimal human intervention\n",
    "\n",
    "Real-world Implementation Examples:\n",
    "- Conversational AI: ChatGPT, Claude, Bard with tool integration\n",
    "- Robotics: Autonomous vehicles, manufacturing robots, service robots\n",
    "- Gaming AI: NPCs with adaptive behavior and learning capabilities\n",
    "- Business Process Automation: Workflow optimization and task execution\n",
    "- Research Assistants: Literature review, hypothesis generation, experiment design\n",
    "\"\"\"\n",
    "\n",
    "    doc1.add_section(\"AI Agents: Foundations and Architecture\", ai_agents_content)\n",
    "\n",
    "    # Enhanced LangChain content\n",
    "    langchain_content = f\"\"\"\n",
    "LANGCHAIN FRAMEWORK OVERVIEW\n",
    "{scraped_content.get('langchain_intro', '')}\n",
    "\n",
    "CORE COMPONENTS AND ARCHITECTURE\n",
    "{scraped_content.get('langchain_components', '')}\n",
    "\n",
    "Detailed Component Breakdown:\n",
    "- LLMs and Chat Models: Integration with OpenAI, Anthropic, Google, local models\n",
    "- Prompt Templates: Dynamic prompt construction with variables and formatting\n",
    "- Output Parsers: Structured data extraction from LLM responses\n",
    "- Memory Systems: Conversation buffers, summaries, and vector-based memory\n",
    "- Retrievers: Document search, web search, and knowledge base integration\n",
    "- Agents and Tools: Function calling and external API integration\n",
    "\n",
    "CHAINS AND WORKFLOWS\n",
    "{scraped_content.get('langchain_chains', '')}\n",
    "\n",
    "Chain Types and Use Cases:\n",
    "- Sequential Chains: Linear processing pipelines for multi-step tasks\n",
    "- Router Chains: Dynamic routing based on input classification\n",
    "- Transform Chains: Data preprocessing and format conversion\n",
    "- Map-Reduce Chains: Parallel processing with result aggregation\n",
    "- Constitutional AI Chains: Self-correction and alignment mechanisms\n",
    "\"\"\"\n",
    "\n",
    "    doc1.add_section(\"LangChain Framework Deep Dive\", langchain_content)\n",
    "\n",
    "    # Add remaining sections\n",
    "    doc1.add_section(\"LangGraph Multi-Agent Orchestration\",\n",
    "                    f\"{scraped_content.get('langgraph_overview', '')}\\n\\n{scraped_content.get('langgraph_tutorial', '')}\")\n",
    "\n",
    "    doc1.add_section(\"LangSmith Development Platform\",\n",
    "                    f\"{scraped_content.get('langsmith_platform', '')}\\n\\n{scraped_content.get('langsmith_features', '')}\")\n",
    "\n",
    "    doc1.save(\"enhanced_document1.pdf\")\n",
    "\n",
    "    # Document 2: RAG and Vector Technologies\n",
    "    doc2 = PDFDocument(\"RAG Systems and Vector Technologies - Technical Implementation Guide\")\n",
    "\n",
    "    rag_comprehensive = f\"\"\"\n",
    "RETRIEVAL-AUGMENTED GENERATION FUNDAMENTALS\n",
    "{scraped_content.get('rag_overview', '')}\n",
    "\n",
    "RAG IMPLEMENTATION STRATEGIES\n",
    "{scraped_content.get('rag_implementation', '')}\n",
    "\n",
    "RAG BEST PRACTICES AND OPTIMIZATION\n",
    "{scraped_content.get('rag_best_practices', '')}\n",
    "\n",
    "Advanced RAG Patterns:\n",
    "- Hierarchical RAG: Multi-level document chunking and retrieval\n",
    "- Adaptive RAG: Dynamic retrieval strategy selection\n",
    "- Self-RAG: Quality assessment and iterative refinement\n",
    "- Multi-modal RAG: Integration of text, images, and structured data\n",
    "- Conversational RAG: Context-aware multi-turn interactions\n",
    "\"\"\"\n",
    "\n",
    "    doc2.add_section(\"Retrieval-Augmented Generation\", rag_comprehensive)\n",
    "\n",
    "    vector_db_comprehensive = f\"\"\"\n",
    "VECTOR DATABASE FUNDAMENTALS\n",
    "{scraped_content.get('vector_databases', '')}\n",
    "\n",
    "VECTOR DATABASE COMPARISON AND SELECTION\n",
    "{scraped_content.get('vector_db_comparison', '')}\n",
    "\n",
    "CHROMADB IMPLEMENTATION GUIDE\n",
    "{scraped_content.get('chromadb_guide', '')}\n",
    "\n",
    "Technical Implementation Details:\n",
    "- Index Types: HNSW, IVF, Flat, Product Quantization\n",
    "- Distance Metrics: Cosine similarity, Euclidean, Dot product, Hamming\n",
    "- Scalability Patterns: Sharding, replication, distributed architectures\n",
    "- Performance Optimization: Batch processing, caching, preprocessing\n",
    "- Integration Strategies: API design, SDK usage, deployment patterns\n",
    "\"\"\"\n",
    "\n",
    "    doc2.add_section(\"Vector Databases and Similarity Search\", vector_db_comprehensive)\n",
    "\n",
    "    embeddings_comprehensive = f\"\"\"\n",
    "EMBEDDING TECHNOLOGIES OVERVIEW\n",
    "{scraped_content.get('embeddings_overview', '')}\n",
    "\n",
    "SENTENCE TRANSFORMERS AND APPLICATIONS\n",
    "{scraped_content.get('sentence_transformers', '')}\n",
    "\n",
    "OPENAI EMBEDDINGS AND API INTEGRATION\n",
    "{scraped_content.get('openai_embeddings', '')}\n",
    "\n",
    "Embedding Model Comparison:\n",
    "- General Purpose: all-MiniLM-L6-v2, all-mpnet-base-v2\n",
    "- Multilingual: paraphrase-multilingual-MiniLM-L12-v2\n",
    "- Domain Specific: BioBERT, FinBERT, LegalBERT\n",
    "- Large Scale: OpenAI ada-002, Cohere embed-english-v3.0\n",
    "- Open Source: BGE-large, E5-large-v2, Instructor embeddings\n",
    "\"\"\"\n",
    "\n",
    "    doc2.add_section(\"Embedding Technologies and Models\", embeddings_comprehensive)\n",
    "\n",
    "    doc2.save(\"enhanced_document2.pdf\")\n",
    "\n",
    "    # Document 3: LLM Foundations and Training\n",
    "    doc3 = PDFDocument(\"Large Language Models: Architecture, Training, and Optimization\")\n",
    "\n",
    "    transformer_comprehensive = f\"\"\"\n",
    "TRANSFORMER ARCHITECTURE DEEP DIVE\n",
    "{scraped_content.get('transformers_architecture', '')}\n",
    "\n",
    "ATTENTION MECHANISMS EXPLAINED\n",
    "{scraped_content.get('attention_mechanism', '')}\n",
    "\n",
    "TRANSFORMER TUTORIAL AND IMPLEMENTATION\n",
    "{scraped_content.get('transformer_tutorial', '')}\n",
    "\n",
    "Architecture Components:\n",
    "- Multi-Head Attention: Parallel attention computation with different representations\n",
    "- Position Encoding: Sinusoidal and learned positional information\n",
    "- Feed-Forward Networks: Point-wise fully connected layers\n",
    "- Layer Normalization: Stabilization and convergence acceleration\n",
    "- Residual Connections: Gradient flow and training stability\n",
    "\"\"\"\n",
    "\n",
    "    doc3.add_section(\"Transformer Architecture\", transformer_comprehensive)\n",
    "\n",
    "    training_comprehensive = f\"\"\"\n",
    "PRE-TRAINING METHODOLOGIES\n",
    "{scraped_content.get('pretraining_methods', '')}\n",
    "\n",
    "SCALING LAWS AND MODEL SIZE\n",
    "{scraped_content.get('scaling_laws', '')}\n",
    "\n",
    "FINE-TUNING STRATEGIES AND IMPLEMENTATION\n",
    "{scraped_content.get('fine_tuning_overview', '')}\n",
    "\n",
    "LLM TRAINING PIPELINES\n",
    "{scraped_content.get('llm_training', '')}\n",
    "\n",
    "Training Optimization Techniques:\n",
    "- Gradient Checkpointing: Memory efficiency during backpropagation\n",
    "- Mixed Precision Training: FP16/BF16 for speed and memory optimization\n",
    "- Data Parallelism: Multi-GPU training strategies\n",
    "- Model Parallelism: Large model distribution across devices\n",
    "- Optimizer Selection: AdamW, Lion, Sophia optimization algorithms\n",
    "\"\"\"\n",
    "\n",
    "    doc3.add_section(\"LLM Training and Optimization\", training_comprehensive)\n",
    "\n",
    "    doc3.save(\"enhanced_document3.pdf\")\n",
    "\n",
    "    # Document 4: Advanced Prompting and Multi-modal AI\n",
    "    doc4 = PDFDocument(\"Advanced Prompt Engineering and Multi-modal AI Systems\")\n",
    "\n",
    "    prompting_comprehensive = f\"\"\"\n",
    "PROMPT ENGINEERING FUNDAMENTALS\n",
    "{scraped_content.get('prompt_engineering', '')}\n",
    "\n",
    "CHAIN-OF-THOUGHT REASONING\n",
    "{scraped_content.get('chain_of_thought', '')}\n",
    "\n",
    "FEW-SHOT LEARNING TECHNIQUES\n",
    "{scraped_content.get('few_shot_prompting', '')}\n",
    "\n",
    "Advanced Prompting Strategies:\n",
    "- Tree of Thoughts: Multi-path reasoning exploration\n",
    "- Self-Consistency: Multiple reasoning paths with majority voting\n",
    "- Program-Aided Language Models: Code generation for complex reasoning\n",
    "- Constitutional AI: Self-correction and alignment through principles\n",
    "- In-Context Learning: Task adaptation without parameter updates\n",
    "\"\"\"\n",
    "\n",
    "    doc4.add_section(\"Advanced Prompt Engineering\", prompting_comprehensive)\n",
    "\n",
    "    multimodal_comprehensive = f\"\"\"\n",
    "MULTI-MODAL LEARNING OVERVIEW\n",
    "{scraped_content.get('multimodal_overview', '')}\n",
    "\n",
    "VISION-LANGUAGE MODELS\n",
    "{scraped_content.get('vision_language_models', '')}\n",
    "\n",
    "Multi-modal Architecture Patterns:\n",
    "- Cross-Modal Attention: Interaction between different modalities\n",
    "- Fusion Strategies: Early, late, and intermediate fusion approaches\n",
    "- Alignment Techniques: Contrastive learning and cross-modal objectives\n",
    "- Generation Capabilities: Text-to-image, image-to-text, multi-modal generation\n",
    "- Applications: Visual question answering, image captioning, document analysis\n",
    "\"\"\"\n",
    "\n",
    "    doc4.add_section(\"Multi-modal AI Systems\", multimodal_comprehensive)\n",
    "\n",
    "    doc4.save(\"enhanced_document4.pdf\")\n",
    "\n",
    "    # Document 5: Protocols and Production Systems\n",
    "    doc5 = PDFDocument(\"Model Context Protocol and Production AI Systems\")\n",
    "\n",
    "    mcp_comprehensive = f\"\"\"\n",
    "MODEL CONTEXT PROTOCOL OVERVIEW\n",
    "{scraped_content.get('mcp_protocol', '')}\n",
    "\n",
    "MCP IMPLEMENTATION AND STANDARDS\n",
    "{scraped_content.get('model_context_protocol', '')}\n",
    "\n",
    "Protocol Features and Benefits:\n",
    "- Standardized Communication: Unified interface for model interactions\n",
    "- Context Management: Efficient context passing and state management\n",
    "- Tool Integration: Seamless external tool and API integration\n",
    "- Security Framework: Authentication and authorization mechanisms\n",
    "- Scalability Support: Load balancing and distributed processing\n",
    "\"\"\"\n",
    "\n",
    "    doc5.add_section(\"Model Context Protocol\", mcp_comprehensive)\n",
    "\n",
    "    production_content = \"\"\"\n",
    "PRODUCTION AI SYSTEM ARCHITECTURE\n",
    "- Microservices Design: Modular, scalable, and maintainable architecture\n",
    "- API Gateway: Rate limiting, authentication, and request routing\n",
    "- Load Balancing: Traffic distribution and failover mechanisms\n",
    "- Caching Strategies: Redis, Memcached for response optimization\n",
    "- Monitoring and Observability: Metrics, logging, and alerting systems\n",
    "\n",
    "MLOPs FOR LARGE LANGUAGE MODELS\n",
    "- Version Control: Model versioning with DVC and MLflow\n",
    "- Continuous Integration: Automated testing and validation pipelines\n",
    "- Deployment Strategies: Blue-green, canary, and rolling deployments\n",
    "- A/B Testing: Experimentation framework for model comparison\n",
    "- Data Drift Detection: Statistical monitoring of input distributions\n",
    "\n",
    "SECURITY AND COMPLIANCE\n",
    "- Data Privacy: Encryption, anonymization, and retention policies\n",
    "- Model Security: Adversarial attack prevention and robustness testing\n",
    "- Regulatory Compliance: GDPR, CCPA, AI Act requirements\n",
    "- Ethical AI: Bias detection, fairness metrics, and responsible AI practices\n",
    "- Audit Trails: Comprehensive logging for compliance and debugging\n",
    "\"\"\"\n",
    "\n",
    "    doc5.add_section(\"Production AI Systems\", production_content)\n",
    "\n",
    "    doc5.save(\"enhanced_document5.pdf\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENHANCED DOCUMENT CREATION COMPLETED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Created documents with comprehensive web-sourced content:\")\n",
    "    print(\"- enhanced_document1.pdf: AI Agents and LangChain Ecosystem\")\n",
    "    print(\"- enhanced_document2.pdf: RAG Systems and Vector Technologies\")\n",
    "    print(\"- enhanced_document3.pdf: LLM Foundations and Training\")\n",
    "    print(\"- enhanced_document4.pdf: Advanced Prompting and Multi-modal AI\")\n",
    "    print(\"- enhanced_document5.pdf: Model Context Protocol and Production Systems\")\n",
    "    print(\"\\nTo integrate with your RAG system:\")\n",
    "    print(\"file_paths = ['enhanced_document1.pdf', 'enhanced_document2.pdf', 'enhanced_document3.pdf', 'enhanced_document4.pdf', 'enhanced_document5.pdf']\")\n",
    "    print(\"documents = process_documents(file_paths)\")\n",
    "    print(\"collection = setup_vector_database()\")\n",
    "    print(\"index_documents(collection, documents)\")\n",
    "\n",
    "# Run the enhanced document creation\n",
    "create_comprehensive_documents()"
   ],
   "id": "d1a9325cc039562e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive document creation with enhanced web scraping...\n",
      "Scraping 1/33: ai_agents_overview...\n",
      "Scraping 2/33: ai_agents_architecture...\n",
      "Scraping 3/33: ai_agents_types...\n",
      "Scraping 4/33: langchain_intro...\n",
      "Scraping 5/33: langchain_components...\n",
      "Scraping 6/33: langchain_chains...\n",
      "Scraping 7/33: langgraph_overview...\n",
      "Scraping 8/33: langgraph_tutorial...\n",
      "Scraping 9/33: langsmith_platform...\n",
      "Scraping 10/33: langsmith_features...\n",
      "Scraping 11/33: rag_overview...\n",
      "Scraping 12/33: rag_implementation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 13/33: rag_best_practices...\n",
      "Scraping 14/33: vector_databases...\n",
      "Scraping 15/33: vector_db_comparison...\n",
      "Scraping 16/33: chromadb_guide...\n",
      "Scraping 17/33: embeddings_overview...\n",
      "Scraping 18/33: sentence_transformers...\n",
      "Scraping 19/33: openai_embeddings...\n",
      "Scraping 20/33: transformers_architecture...\n",
      "Scraping 21/33: attention_mechanism...\n",
      "Scraping 22/33: transformer_tutorial...\n",
      "Scraping 23/33: prompt_engineering...\n",
      "Scraping 24/33: chain_of_thought...\n",
      "Scraping 25/33: few_shot_prompting...\n",
      "Scraping 26/33: fine_tuning_overview...\n",
      "Scraping 27/33: llm_training...\n",
      "Scraping 28/33: multimodal_overview...\n",
      "Scraping 29/33: vision_language_models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 30/33: mcp_protocol...\n",
      "Scraping 31/33: model_context_protocol...\n",
      "Scraping 32/33: pretraining_methods...\n",
      "Scraping 33/33: scaling_laws...\n",
      "Successfully saved enhanced_document1.pdf\n",
      "Successfully saved enhanced_document2.pdf\n",
      "Successfully saved enhanced_document3.pdf\n",
      "Successfully saved enhanced_document4.pdf\n",
      "Successfully saved enhanced_document5.pdf\n",
      "\n",
      "============================================================\n",
      "ENHANCED DOCUMENT CREATION COMPLETED!\n",
      "============================================================\n",
      "Created documents with comprehensive web-sourced content:\n",
      "- enhanced_document1.pdf: AI Agents and LangChain Ecosystem\n",
      "- enhanced_document2.pdf: RAG Systems and Vector Technologies\n",
      "- enhanced_document3.pdf: LLM Foundations and Training\n",
      "- enhanced_document4.pdf: Advanced Prompting and Multi-modal AI\n",
      "- enhanced_document5.pdf: Model Context Protocol and Production Systems\n",
      "\n",
      "To integrate with your RAG system:\n",
      "file_paths = ['enhanced_document1.pdf', 'enhanced_document2.pdf', 'enhanced_document3.pdf', 'enhanced_document4.pdf', 'enhanced_document5.pdf']\n",
      "documents = process_documents(file_paths)\n",
      "collection = setup_vector_database()\n",
      "index_documents(collection, documents)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:48:12.013194Z",
     "start_time": "2025-07-19T12:48:11.969294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Creating enhanced documents with web scraping...\")\n",
    "create_enhanced_documents()\n",
    "\n",
    "print(\"\\nEnhanced documents created successfully!\")\n",
    "print(\"- document1.pdf: AI Agents and LangChain Ecosystem - Advanced Guide\")\n",
    "print(\"- document2.pdf: Large Language Model Foundations - Technical Deep Dive\")\n",
    "print(\"- document3.pdf: Vector Databases and Semantic Search\")\n",
    "print(\"- document4.pdf: Advanced Prompt Engineering and Multi-modal AI\")\n",
    "print(\"- document5.pdf: Production AI Systems and MLOps\")\n",
    "print(\"\\nIntegration with your RAG system:\")\n",
    "print(\"file_paths = ['document1.pdf', 'document2.pdf', 'document3.pdf', 'document4.pdf', 'document5.pdf']\")\n",
    "print(\"documents = process_documents(file_paths)\")\n",
    "print(\"collection = setup_vector_database()\")\n",
    "print(\"index_documents(collection, documents)\")"
   ],
   "id": "cba4040d5ed587ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced documents with web scraping...\n",
      "Successfully saved document1.pdf\n",
      "Successfully saved document2.pdf\n",
      "Successfully saved document3.pdf\n",
      "Successfully saved document4.pdf\n",
      "Successfully saved document5.pdf\n",
      "\n",
      "Enhanced documents created successfully!\n",
      "- document1.pdf: AI Agents and LangChain Ecosystem - Advanced Guide\n",
      "- document2.pdf: Large Language Model Foundations - Technical Deep Dive\n",
      "- document3.pdf: Vector Databases and Semantic Search\n",
      "- document4.pdf: Advanced Prompt Engineering and Multi-modal AI\n",
      "- document5.pdf: Production AI Systems and MLOps\n",
      "\n",
      "Integration with your RAG system:\n",
      "file_paths = ['document1.pdf', 'document2.pdf', 'document3.pdf', 'document4.pdf', 'document5.pdf']\n",
      "documents = process_documents(file_paths)\n",
      "collection = setup_vector_database()\n",
      "index_documents(collection, documents)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d6623645c24d561e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
