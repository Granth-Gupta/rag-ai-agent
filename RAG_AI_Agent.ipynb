{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment Configuration",
   "id": "24f7b7a7c091bd34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:49:44.517423Z",
     "start_time": "2025-07-19T12:49:44.510367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict, NotRequired\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ],
   "id": "ade1b75610f77127",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating the Semantic Database",
   "id": "46929e26c00dc282"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Document Processing and Embedding",
   "id": "3383bfec6162d00b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:49:51.093824Z",
     "start_time": "2025-07-19T12:49:46.371382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Document processing\n",
    "def process_documents(file_paths):\n",
    "    docs = []\n",
    "    for path in file_paths:\n",
    "        if path.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(path)\n",
    "        else:\n",
    "            loader = WebBaseLoader(path)\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,  # Increased for better context\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs)\n",
    "    return doc_splits\n",
    "\n",
    "\n",
    "# file_paths = [\"document1.pdf\", \"document2.pdf\"]\n",
    "# documents = process_documents(file_paths)\n"
   ],
   "id": "1007854114208f38",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Vector Database Setup",
   "id": "ae979debed96b5ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.307893Z",
     "start_time": "2025-07-19T12:49:51.108816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize ChromaDB for semantic search\n",
    "def setup_vector_database():\n",
    "    client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=\"documents\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    return collection\n",
    "\n",
    "# Add documents to vector database\n",
    "def index_documents(collection, documents):\n",
    "    print(f\"Indexing {len(documents)} document chunks...\")\n",
    "    for i, doc in enumerate(documents):\n",
    "        embedding = embedding_model.encode(doc.page_content)\n",
    "        collection.add(\n",
    "            embeddings=[embedding.tolist()],\n",
    "            documents=[doc.page_content],\n",
    "            metadatas=[doc.metadata],\n",
    "            ids=[f\"doc_{i}\"]\n",
    "        )\n",
    "    print(\"Document indexing completed!\")\n",
    "\n",
    "# Setup with 5 documents\n",
    "file_paths = [\"document1.pdf\", \"document2.pdf\", \"document3.pdf\", \"document4.pdf\", \"document5.pdf\"]\n",
    "documents = process_documents(file_paths)\n",
    "collection = setup_vector_database()\n",
    "index_documents(collection, documents)"
   ],
   "id": "31479bb76c8b3c6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing 687 document chunks...\n",
      "Document indexing completed!\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Building the RAG Agent with LangGraph",
   "id": "c2fb5144116beee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.329917Z",
     "start_time": "2025-07-19T12:50:19.325920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    context: NotRequired[str]\n",
    "    query_type: NotRequired[str]\n"
   ],
   "id": "ef6cf7354a6fb76e",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.365563Z",
     "start_time": "2025-07-19T12:50:19.353071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tools for the agent\n",
    "@tool\n",
    "def semantic_search(query: str, k: int = 5) -> str:\n",
    "    \"\"\"Perform semantic search on the document collection.\"\"\"\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=k\n",
    "    )\n",
    "\n",
    "    # Format results with relevance scores\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Source {i+1}: {doc}\"\n",
    "        for i, doc in enumerate(results['documents'][0])\n",
    "    ])\n",
    "\n",
    "    return context\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web for real-time information.\"\"\"\n",
    "    # Mock implementation - in practice, integrate with real web search API\n",
    "    return f\"Web search results for: {query}\\n[This would contain real-time web information]\"\n"
   ],
   "id": "2ed76ce94b536572",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.394438Z",
     "start_time": "2025-07-19T12:50:19.390722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize state with default values\n",
    "def create_initial_state(user_message: str) -> AgentState:\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": user_message}],\n",
    "        \"context\": \"\",\n",
    "        \"query_type\": \"semantic_search\"\n",
    "    }"
   ],
   "id": "687fcbaeb73b38cc",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.422438Z",
     "start_time": "2025-07-19T12:50:19.416445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Updated workflow functions with safe state access\n",
    "def query_analyzer(state: AgentState) -> dict:\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    query_lower = last_message.lower()\n",
    "\n",
    "    if any(keyword in query_lower for keyword in [\"recent\", \"current\", \"latest\"]):\n",
    "        query_type = \"web_search\"\n",
    "    else:\n",
    "        query_type = \"semantic_search\"\n",
    "\n",
    "    return {\"query_type\": query_type}\n",
    "\n",
    "def retriever_node(state: AgentState) -> dict:\n",
    "    query = state[\"messages\"][-1].content\n",
    "    query_type = state.get(\"query_type\", \"semantic_search\")\n",
    "\n",
    "    if query_type == \"web_search\":\n",
    "        context = web_search.invoke({\"query\": query})\n",
    "    else:\n",
    "        context = semantic_search.invoke({\"query\": query})\n",
    "\n",
    "    return {\"context\": context}"
   ],
   "id": "884d103a036d76c0",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.444440Z",
     "start_time": "2025-07-19T12:50:19.439572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Updated generator node with proper LLM integration\n",
    "def generator_node(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
    "\n",
    "        query = state['messages'][-1].content\n",
    "        context = state.get('context', 'No relevant context found')\n",
    "\n",
    "        # Properly format the template with actual values\n",
    "        system_prompt = f\"\"\"You are a helpful AI assistant with access to a comprehensive knowledge base about AI agents, LangChain, vector databases, and related technologies.\n",
    "\n",
    "Use the provided context to give detailed, accurate answers. If the context doesn't contain relevant information, say so clearly.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Please provide a comprehensive answer based on the context provided.\"\"\"\n",
    "\n",
    "        response = llm.invoke([HumanMessage(content=system_prompt)])\n",
    "        return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "    except Exception as e:\n",
    "        return generate_fallback_response(state)\n",
    "\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Setup environment variables for different LLM providers.\"\"\"\n",
    "    # For Google\n",
    "    if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "        print(\"Warning: GOOGLE_API_KEY not set. Set it for Google models.\")\n"
   ],
   "id": "4b82ef28d718e952",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.465886Z",
     "start_time": "2025-07-19T12:50:19.461314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_state(state: AgentState) -> bool:\n",
    "    required_keys = [\"messages\"]\n",
    "    return all(key in state for key in required_keys)\n",
    "\n",
    "def safe_get_context(state: AgentState) -> str:\n",
    "    return state.get(\"context\", \"No context available\")\n",
    "\n",
    "def safe_get_query_type(state: AgentState) -> str:\n",
    "    return state.get(\"query_type\", \"semantic_search\")\n"
   ],
   "id": "34eb8a1b295af5f9",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:19.489993Z",
     "start_time": "2025-07-19T12:50:19.482122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the RAG agent\n",
    "def build_rag_agent():\n",
    "    # Initialize memory\n",
    "    memory = MemorySaver()\n",
    "\n",
    "    # Create state graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Add nodes\n",
    "    workflow.add_node(\"analyzer\", query_analyzer)\n",
    "    workflow.add_node(\"retriever\", retriever_node)\n",
    "    workflow.add_node(\"generator\", generator_node)\n",
    "\n",
    "    # Define edges\n",
    "    workflow.add_edge(START, \"analyzer\")\n",
    "    workflow.add_edge(\"analyzer\", \"retriever\")\n",
    "    workflow.add_edge(\"retriever\", \"generator\")\n",
    "    workflow.add_edge(\"generator\", END)\n",
    "\n",
    "    # Compile with memory\n",
    "    agent = workflow.compile(checkpointer=memory)\n",
    "\n",
    "    return agent\n",
    "\n",
    "# Initialize the agent\n",
    "agent = build_rag_agent()"
   ],
   "id": "b5ddd8646a822af0",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:50:20.059178Z",
     "start_time": "2025-07-19T12:50:19.505932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ],
   "id": "2b831d5565a95c34",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing Framework",
   "id": "40571ac277c159a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T12:51:25.390050Z",
     "start_time": "2025-07-19T12:51:07.583230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def enhanced_test_suite():\n",
    "    \"\"\"Run enhanced tests with proper response validation.\"\"\"\n",
    "\n",
    "    # Setup environment\n",
    "    setup_environment()\n",
    "\n",
    "    # Test configuration\n",
    "    config = {\"configurable\": {\"thread_id\": \"enhanced_test_session\"}}\n",
    "\n",
    "    # Enhanced test queries\n",
    "    test_queries = [\n",
    "        {\n",
    "            \"query\": \"What are the core features of AI agents and how do they achieve autonomy?\",\n",
    "            \"expected_topics\": [\"autonomous\", \"goal-oriented\", \"reasoning\", \"planning\", \"memory\"],\n",
    "            \"min_length\": 200\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Explain how LangChain chains work and their integration capabilities\",\n",
    "            \"expected_topics\": [\"chains\", \"prompts\", \"integration\", \"workflows\", \"tools\"],\n",
    "            \"min_length\": 200\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Describe the architecture and similarity search in vector databases\",\n",
    "            \"expected_topics\": [\"embeddings\", \"similarity\", \"indexing\", \"HNSW\", \"retrieval\"],\n",
    "            \"min_length\": 200\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"What is RAG and how does it enhance language model responses?\",\n",
    "            \"expected_topics\": [\"retrieval\", \"generation\", \"augmented\", \"context\", \"documents\"],\n",
    "            \"min_length\": 200\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"What are advanced prompt engineering strategies for better LLM performance?\",\n",
    "            \"expected_topics\": [\"chain-of-thought\", \"few-shot\", \"optimization\", \"templates\", \"evaluation\"],\n",
    "            \"min_length\": 200\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, test_case in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ENHANCED TEST {i}: {test_case['query']}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        try:\n",
    "            # Execute query\n",
    "            response = agent.invoke(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": test_case['query']}]},\n",
    "                config=config\n",
    "            )\n",
    "\n",
    "            # Extract response content\n",
    "            response_content = response['messages'][-1].content\n",
    "\n",
    "            # Enhanced validation\n",
    "            found_topics = []\n",
    "            for topic in test_case['expected_topics']:\n",
    "                if topic.lower() in response_content.lower():\n",
    "                    found_topics.append(topic)\n",
    "\n",
    "            relevance_score = len(found_topics) / len(test_case['expected_topics'])\n",
    "            length_check = len(response_content) >= test_case['min_length']\n",
    "\n",
    "            # Display results\n",
    "            print(f\"\\nQUERY: {test_case['query']}\")\n",
    "            print(f\"\\nRESPONSE:\\n{response_content[:300]}...\")\n",
    "            print(f\"\\nVALIDATION:\")\n",
    "            print(f\"Expected topics: {test_case['expected_topics']}\")\n",
    "            print(f\"Found topics: {found_topics}\")\n",
    "            print(f\"Relevance score: {relevance_score:.2%}\")\n",
    "            print(f\"Response length: {len(response_content)} chars (min: {test_case['min_length']})\")\n",
    "            print(f\"Length check: {'✅ PASS' if length_check else '❌ FAIL'}\")\n",
    "\n",
    "            # Overall assessment\n",
    "            overall_pass = relevance_score >= 0.6 and length_check\n",
    "            print(f\"Overall: {'✅ PASS' if overall_pass else '❌ FAIL'}\")\n",
    "\n",
    "            results.append({\n",
    "                \"query\": test_case['query'],\n",
    "                \"response_length\": len(response_content),\n",
    "                \"relevance_score\": relevance_score,\n",
    "                \"length_check\": length_check,\n",
    "                \"overall_pass\": overall_pass,\n",
    "                \"status\": \"SUCCESS\"\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {str(e)}\")\n",
    "            results.append({\n",
    "                \"query\": test_case['query'],\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"FAILED\"\n",
    "            })\n",
    "\n",
    "    # Enhanced summary report\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ENHANCED TEST SUMMARY REPORT\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    successful_tests = [r for r in results if r['status'] == 'SUCCESS']\n",
    "    failed_tests = [r for r in results if r['status'] == 'FAILED']\n",
    "    passed_tests = [r for r in successful_tests if r.get('overall_pass', False)]\n",
    "\n",
    "    print(f\"Total tests: {len(results)}\")\n",
    "    print(f\"Successful executions: {len(successful_tests)}\")\n",
    "    print(f\"Failed executions: {len(failed_tests)}\")\n",
    "    print(f\"Overall passed: {len(passed_tests)}\")\n",
    "    print(f\"Pass rate: {len(passed_tests)/len(results)*100:.1f}%\")\n",
    "\n",
    "    if successful_tests:\n",
    "        avg_relevance = sum(r['relevance_score'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_response_length = sum(r['response_length'] for r in successful_tests) / len(successful_tests)\n",
    "\n",
    "        print(f\"Average relevance score: {avg_relevance:.2%}\")\n",
    "        print(f\"Average response length: {avg_response_length:.0f} characters\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize the enhanced agent\n",
    "setup_environment()\n",
    "enhanced_results = enhanced_test_suite()"
   ],
   "id": "f53784001a63c5a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ENHANCED TEST 1: What are the core features of AI agents and how do they achieve autonomy?\n",
      "======================================================================\n",
      "\n",
      "QUERY: What are the core features of AI agents and how do they achieve autonomy?\n",
      "\n",
      "RESPONSE:\n",
      "Based on the provided context, here's a breakdown of the core features of AI agents and how they achieve autonomy:\n",
      "\n",
      "**Core Features of AI Agents:**\n",
      "\n",
      "*   **Autonomy:** AI agents possess a high degree of autonomy, enabling them to operate and make decisions independently to achieve a goal (Source 1).\n",
      "...\n",
      "\n",
      "VALIDATION:\n",
      "Expected topics: ['autonomous', 'goal-oriented', 'reasoning', 'planning', 'memory']\n",
      "Found topics: ['goal-oriented', 'reasoning', 'planning', 'memory']\n",
      "Relevance score: 80.00%\n",
      "Response length: 1678 chars (min: 200)\n",
      "Length check: ✅ PASS\n",
      "Overall: ✅ PASS\n",
      "\n",
      "======================================================================\n",
      "ENHANCED TEST 2: Explain how LangChain chains work and their integration capabilities\n",
      "======================================================================\n",
      "\n",
      "QUERY: Explain how LangChain chains work and their integration capabilities\n",
      "\n",
      "RESPONSE:\n",
      "LangChain facilitates the creation of structured workflows by connecting multiple Language Model (LLM) components using modular building blocks like chains, agents, and memory. These chains enable the integration of LLMs with external tools, APIs, and data sources, which allows for the development o...\n",
      "\n",
      "VALIDATION:\n",
      "Expected topics: ['chains', 'prompts', 'integration', 'workflows', 'tools']\n",
      "Found topics: ['chains', 'integration', 'workflows', 'tools']\n",
      "Relevance score: 80.00%\n",
      "Response length: 867 chars (min: 200)\n",
      "Length check: ✅ PASS\n",
      "Overall: ✅ PASS\n",
      "\n",
      "======================================================================\n",
      "ENHANCED TEST 3: Describe the architecture and similarity search in vector databases\n",
      "======================================================================\n",
      "\n",
      "QUERY: Describe the architecture and similarity search in vector databases\n",
      "\n",
      "RESPONSE:\n",
      "Here's a breakdown of the architecture and similarity search in vector databases, based on the provided context:\n",
      "\n",
      "**Architecture:**\n",
      "\n",
      "*   **Vector Space Model:** Vector databases use the vector space model to store data. This means data is represented as vectors (fixed-length lists of numbers) in a h...\n",
      "\n",
      "VALIDATION:\n",
      "Expected topics: ['embeddings', 'similarity', 'indexing', 'HNSW', 'retrieval']\n",
      "Found topics: ['embeddings', 'similarity']\n",
      "Relevance score: 40.00%\n",
      "Response length: 1751 chars (min: 200)\n",
      "Length check: ✅ PASS\n",
      "Overall: ❌ FAIL\n",
      "\n",
      "======================================================================\n",
      "ENHANCED TEST 4: What is RAG and how does it enhance language model responses?\n",
      "======================================================================\n",
      "\n",
      "QUERY: What is RAG and how does it enhance language model responses?\n",
      "\n",
      "RESPONSE:\n",
      "RAG, or Retrieval-Augmented Generation, is a technique that enhances large language models (LLMs) by incorporating information retrieval into the response generation process. Instead of relying solely on static training data, RAG pulls relevant information from external sources like databases, uploa...\n",
      "\n",
      "VALIDATION:\n",
      "Expected topics: ['retrieval', 'generation', 'augmented', 'context', 'documents']\n",
      "Found topics: ['retrieval', 'generation', 'augmented', 'context', 'documents']\n",
      "Relevance score: 100.00%\n",
      "Response length: 1438 chars (min: 200)\n",
      "Length check: ✅ PASS\n",
      "Overall: ✅ PASS\n",
      "\n",
      "======================================================================\n",
      "ENHANCED TEST 5: What are advanced prompt engineering strategies for better LLM performance?\n",
      "======================================================================\n",
      "\n",
      "QUERY: What are advanced prompt engineering strategies for better LLM performance?\n",
      "\n",
      "RESPONSE:\n",
      "Based on the provided context, here's what I can tell you about advanced prompt engineering strategies for better LLM performance:\n",
      "\n",
      "*   **General Definition:** Prompt engineering is a discipline focused on developing and optimizing prompts to efficiently use language models (LLMs) for various applic...\n",
      "\n",
      "VALIDATION:\n",
      "Expected topics: ['chain-of-thought', 'few-shot', 'optimization', 'templates', 'evaluation']\n",
      "Found topics: []\n",
      "Relevance score: 0.00%\n",
      "Response length: 1100 chars (min: 200)\n",
      "Length check: ✅ PASS\n",
      "Overall: ❌ FAIL\n",
      "\n",
      "======================================================================\n",
      "ENHANCED TEST SUMMARY REPORT\n",
      "======================================================================\n",
      "Total tests: 5\n",
      "Successful executions: 5\n",
      "Failed executions: 0\n",
      "Overall passed: 3\n",
      "Pass rate: 60.0%\n",
      "Average relevance score: 60.00%\n",
      "Average response length: 1367 characters\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c4ffc3b5faac089"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "aaaaa## Advanced Features",
   "id": "7247ac7725fc3d19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Multi-Modal RAG Support",
   "id": "178c63ce612b476a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T14:43:52.424501Z",
     "start_time": "2025-07-18T14:43:52.414710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tool\n",
    "def image_analyzer(image_path: str) -> str:\n",
    "    \"\"\"Analyze images and extract text/information.\"\"\"\n",
    "    # Implement image processing logic\n",
    "    return f\"Image analysis results for: {image_path}\"\n",
    "\n",
    "@tool\n",
    "def document_qa(question: str, doc_type: str = \"pdf\") -> str:\n",
    "    \"\"\"Answer questions about specific document types.\"\"\"\n",
    "    # Implement document-specific QA\n",
    "    return f\"Document QA response for: {question}\"\n"
   ],
   "id": "39b1c3810b554c53",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Contextual Memory Integration",
   "id": "73e52eb7da137367"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T14:44:12.180691Z",
     "start_time": "2025-07-18T14:44:12.176782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MemoryEnhancedState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    context: str\n",
    "    query_type: str\n",
    "    conversation_history: list\n",
    "    user_preferences: dict\n",
    "\n",
    "def memory_enhanced_generator(state: MemoryEnhancedState) -> MemoryEnhancedState:\n",
    "    \"\"\"Generate responses with conversation memory.\"\"\"\n",
    "    # Access previous conversations\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    preferences = state.get(\"user_preferences\", {})\n",
    "\n",
    "    # Generate contextualized response\n",
    "    # Implementation details...\n"
   ],
   "id": "1c9674c8362958f9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Semantic Caching for Performance",
   "id": "6ed6355aef06bb58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T14:44:30.334852Z",
     "start_time": "2025-07-18T14:44:30.328448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "from functools import lru_cache\n",
    "\n",
    "class SemanticCache:\n",
    "    def __init__(self, similarity_threshold=0.8):\n",
    "        self.cache = {}\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "\n",
    "    def get_cached_response(self, query: str):\n",
    "        query_embedding = embedding_model.encode(query)\n",
    "\n",
    "        # Check for similar queries in cache\n",
    "        for cached_query, (cached_embedding, response) in self.cache.items():\n",
    "            similarity = cosine_similarity([query_embedding], [cached_embedding])[0][0]\n",
    "            if similarity > self.similarity_threshold:\n",
    "                return response\n",
    "\n",
    "        return None\n",
    "\n",
    "    def cache_response(self, query: str, response: str):\n",
    "        query_embedding = embedding_model.encode(query)\n",
    "        self.cache[query] = (query_embedding, response)\n"
   ],
   "id": "f12c6373e03171b6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Deployment and Testing",
   "id": "938031a9c1cdac35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Testing the RAG System",
   "id": "92cc6314ebc03868"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T14:45:05.230891Z",
     "start_time": "2025-07-18T14:45:05.225800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_rag_agent():\n",
    "    # Initialize agent\n",
    "    agent = build_rag_agent()\n",
    "\n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"What is the main topic of the documents?\",\n",
    "        \"Can you summarize the key findings?\",\n",
    "        \"How does this relate to current trends?\"\n",
    "    ]\n",
    "\n",
    "    for query in test_queries:\n",
    "        config = {\"configurable\": {\"thread_id\": \"test_session\"}}\n",
    "\n",
    "        response = agent.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Response: {response['messages'][-1].content}\")\n",
    "        print(\"-\" * 50)\n"
   ],
   "id": "c729a45d8d93ffaf",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Performance Optimization",
   "id": "31339bad39bf47c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T14:45:23.927704Z",
     "start_time": "2025-07-18T14:45:23.924320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Implement query routing for better performance\n",
    "def route_query(query: str) -> str:\n",
    "    \"\"\"Route queries to appropriate processing pipelines.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    if any(keyword in query_lower for keyword in [\"calculate\", \"compute\", \"math\"]):\n",
    "        return \"computational\"\n",
    "    elif any(keyword in query_lower for keyword in [\"recent\", \"latest\", \"current\"]):\n",
    "        return \"web_search\"\n",
    "    else:\n",
    "        return \"semantic_search\"\n"
   ],
   "id": "671b9d4ba4b47b4b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "80f2959055e8c714"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
